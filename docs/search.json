[
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "Teaching",
    "section": "",
    "text": "CS3483 (2025) ‚Äî Multi-model Interface Design."
  },
  {
    "objectID": "teaching/index.html#current-courses",
    "href": "teaching/index.html#current-courses",
    "title": "Teaching",
    "section": "",
    "text": "CS3483 (2025) ‚Äî Multi-model Interface Design."
  },
  {
    "objectID": "teaching/index.html#past-courses",
    "href": "teaching/index.html#past-courses",
    "title": "Teaching",
    "section": "Past courses",
    "text": "Past courses\n\nCS3481 (2024) ‚Äî Fundamentals of Data Science.\nCS3483 (2023) ‚Äî Multi-model Interface Design."
  },
  {
    "objectID": "posts/index.html",
    "href": "posts/index.html",
    "title": "Posts",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dake Bu",
    "section": "",
    "text": "Âçú Â§ßÂèØ „Éª „Ç¶„É©„Éä„Ç§ „Çø„Ç§„Ç´\nPhd Candidate, Department of Computer Science, City University of Hong Kong.\nHi! I am currently a PhD candidate at Optima Group, Department of Computer Science, City University of Hong Kong, advised by Prof.¬†Hau-San Wong and Prof.¬†Qingfu Zhang since 2023 fall. I‚Äôm also fortunate to work closely with Prof.¬†Wei Huang and Prof.¬†Andi Han. Before that, I completed my bachelor degree in 2023 in Mathematics at Xi‚Äôan Jiaotong University, advised by Prof.¬†Hui Li and mentored by Prof.¬†Jian Sun.\nI am currently an incoming one-year intern at CFAR, A*STAR, where I will be supervised by Prof.¬†Atsushi Nitanda. Prior to this, I spent one year (2024‚Äì2025) as a research intern at the University of Tokyo, working at the Deep Learning Theory Team at RIKEN AIP under the supervision of Prof.¬†Taiji Suzuki. Earlier, from January to May 2023, I was a research assistant in the LOGO Lab at The Chinese University of Hong Kong, advised by Prof.¬†Tianshu Yu.\nMy research broadly covers theoretical foundations of deep learning, distribution optimization, mean-field optimization, sampling and reinforcement learning.\nYou can find a full list of my papers on Google Scholar."
  },
  {
    "objectID": "index.html#news",
    "href": "index.html#news",
    "title": "Dake Bu",
    "section": "News",
    "text": "News\n\n2025-01 ‚Äî Two papers on theoretical foundation of task vector in In-Context Learning, and Multi-objective Reinforcement Learning with Lexicographic Rewards are accepted to ICML 2025.\n\n2024-09 ‚Äî One paper on In context learning with multi-concept word semantics is accepted to NeurIPS 2024.\n\n2024-01 ‚Äî One paper on theoretical foundation of neural active learning accepted to ICML 2025."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Dake Bu",
    "section": "Education",
    "text": "Education\n\nOct.¬†2023 ‚Äì Present ‚Äî PhD Candidate, Department of Computer Science, City University of Hong Kong (CityUHK).\n\nAug.¬†2019 ‚Äì Jun.¬†2023 ‚Äî School of Mathematics and Statistics, Xi‚Äôan Jiaotong University (XJTU)."
  },
  {
    "objectID": "index.html#work-experience",
    "href": "index.html#work-experience",
    "title": "Dake Bu",
    "section": "Work Experience",
    "text": "Work Experience\n\nDec.¬†2025 - Present, - Research Intern, CFAR A*STAR\nDec.¬†2024 - Oct.¬†2023 - Research Intern, RIKEN AIP\nJan.¬†2023- May. 2023 - Research Assistant, The Chinese University of Hong Kong, Shenzhen"
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "Dake Bu",
    "section": "Contact",
    "text": "Contact\n\nAffiliation: Department of Computer Science, City University of Hong Kong\n\nLocation: Singapore\n\nEmail: &lt;dakebu2-c[at]my.cityu[dot]edu[dot]hk&gt;"
  },
  {
    "objectID": "index.html#links",
    "href": "index.html#links",
    "title": "Dake Bu",
    "section": "Links",
    "text": "Links\n\nüìÑ Curriculum Vitae\n\nüìö Google Scholar"
  },
  {
    "objectID": "cv/index.html",
    "href": "cv/index.html",
    "title": "Curriculum Vitae",
    "section": "",
    "text": "I keep my CV as a PDF.\n\nDownload CV (PDF)"
  },
  {
    "objectID": "posts/hello-world.html",
    "href": "posts/hello-world.html",
    "title": "Hello, Quarto",
    "section": "",
    "text": "This is a placeholder post. Replace it with your own content, or delete the posts/ folder if you don‚Äôt want a blog."
  },
  {
    "objectID": "research/index.html",
    "href": "research/index.html",
    "title": "Research",
    "section": "",
    "text": "Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Qingfu Zhang, Hau-San Wong, and Taiji Suzuki. Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training.\nDake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, and Taiji Suzuki. Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning."
  },
  {
    "objectID": "research/index.html#working-papers",
    "href": "research/index.html#working-papers",
    "title": "Research",
    "section": "",
    "text": "Dake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Qingfu Zhang, Hau-San Wong, and Taiji Suzuki. Provable Benefit of Curriculum in Transformer Tree-Reasoning Post-Training.\nDake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Bo Xue, Qingfu Zhang, Hau-San Wong, and Taiji Suzuki. Consistency Is Not Always Correct: Towards Understanding the Role of Exploration in Post-Training Reasoning."
  },
  {
    "objectID": "research/index.html#publications",
    "href": "research/index.html#publications",
    "title": "Research",
    "section": "Publications",
    "text": "Publications\n\nDake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Qingfu Zhang, Hau-San Wong, and Taiji Suzuki. Provable In-Context Vector Arithmetic via Retrieving Task Concepts. The 42nd International Conference on Machine Learning (ICML2025).\nBo Xue, Dake Bu, Ji Cheng, Yuanyu Wan, Qingfu Zhang. Multi-objective Linear Reinforcement Learning with Lexicographic Rewards. The 42nd International Conference on Machine Learning (ICML2025).\nDake Bu, Wei Huang, Andi Han, Atsushi Nitanda, Taiji Suzuki, Qingfu Zhang, Hau-San Wong: Provably Transformers Harness Multi-Concept Word Semantics for Efficient In-Context Learning. Advances in Neural Information Processing Systems 37 (NeurIPS 2024).\nDake Bu, Wei Huang, Taiji Suzuki, Ji Cheng, Qingfu Zhang, Zhiqiang Xu, Hau-San Wong: Provably Neural Active Learning SucceedsviaPrioritizingPerplexingSamples (ICML2024)."
  }
]